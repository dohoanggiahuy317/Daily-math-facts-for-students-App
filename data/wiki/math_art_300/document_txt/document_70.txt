Gradient theorem - Wikipedia Jump to content Main menu Main menu move to sidebar hide Navigation Main page Contents Current events Random article About Wikipedia Contact us Donate Contribute Help Learn to edit Community portal Recent changes Upload file Search Search Appearance Create account Log in Personal tools Create account Log in Pages for logged out editors learn more Contributions Talk Contents move to sidebar hide (Top) 1 Proof 2 Examples Toggle Examples subsection 2.

1 Example 1 2.

2 Example 2 2.

3 Example 3 3 Converse of the gradient theorem Toggle Converse of the gradient theorem subsection 3.

1 Proof of the converse 3.

2 Example of the converse principle 4 Generalizations 5 See also 6 References Toggle the table of contents Gradient theorem 13 languages العربية Bosanski Español Esperanto فارسی Français 한국어 Italiano עברית Português Українська 粵語 中文 Edit links Article Talk English Read Edit View history Tools Tools move to sidebar hide Actions Read Edit View history General What links here Related changes Upload file Special pages Permanent link Page information Cite this page Get shortened URL Download QR code Wikidata item Print/export Download as PDF Printable version Appearance move to sidebar hide From Wikipedia, the free encyclopedia Evaluates a line integral through a gradient field using the original scalar field Part of a series of articles about Calculus ∫ a b f ′ ( t ) d t = f ( b ) − f ( a ) {\displaystyle \int _{a}^{b}f'(t)\,dt=f(b)-f(a)} Fundamental theorem Limits Continuity Rolle's theorem Mean value theorem Inverse function theorem Differential Definitions Derivative ( generalizations ) Differential infinitesimal of a function total Concepts Differentiation notation Second derivative Implicit differentiation Logarithmic differentiation Related rates Taylor's theorem Rules and identities Sum Product Chain Power Quotient L'Hôpital's rule Inverse General Leibniz Faà di Bruno's formula Reynolds Integral Lists of integrals Integral transform Leibniz integral rule Definitions Antiderivative Integral ( improper ) Riemann integral Lebesgue integration Contour integration Integral of inverse functions Integration by Parts Discs Cylindrical shells Substitution ( trigonometric , tangent half-angle , Euler ) Euler's formula Partial fractions Changing order Reduction formulae Differentiating under the integral sign Risch algorithm Series Geometric ( arithmetico-geometric ) Harmonic Alternating Power Binomial Taylor Convergence tests Summand limit (term test) Ratio Root Integral Direct comparison Limit comparison Alternating series Cauchy condensation Dirichlet Abel Vector Gradient Divergence Curl Laplacian Directional derivative Identities Theorems Gradient Green's Stokes' Divergence generalized Stokes Helmholtz decomposition Multivariable Formalisms Matrix Tensor Exterior Geometric Definitions Partial derivative Multiple integral Line integral Surface integral Volume integral Jacobian Hessian Advanced Calculus on Euclidean space Generalized functions Limit of distributions Specialized Fractional Malliavin Stochastic Variations Miscellaneous Precalculus History Glossary List of topics Integration Bee Mathematical analysis Nonstandard analysis v t e The gradient theorem , also known as the fundamental theorem of calculus for line integrals , says that a line integral through a gradient field can be evaluated by evaluating the original scalar field at the endpoints of the curve.

The theorem is a generalization of the second fundamental theorem of calculus to any curve in a plane or space (generally n -dimensional) rather than just the real line.

If φ : U ⊆ R n → R is a differentiable function and γ a differentiable curve in U which starts at a point p and ends at a point q , then ∫ γ ∇ φ ( r ) ⋅ d r = φ ( q ) − φ ( p ) {\displaystyle \int _{\gamma }\nabla \varphi (\mathbf {r} )\cdot \mathrm {d} \mathbf {r} =\varphi \left(\mathbf {q} \right)-\varphi \left(\mathbf {p} \right)} where ∇ φ denotes the gradient vector field of φ.

The gradient theorem implies that line integrals through gradient fields are path-independent.

In physics this theorem is one of the ways of defining a conservative force.

By placing φ as potential, ∇ φ is a conservative field.

Work done by conservative forces does not depend on the path followed by the object, but only the end points, as the above equation shows.

The gradient theorem also has an interesting converse: any path-independent vector field can be expressed as the gradient of a scalar field.

Just like the gradient theorem itself, this converse has many striking consequences and applications in both pure and applied mathematics.

Proof [ edit ] If φ is a differentiable function from some open subset U ⊆ R n to R and r is a differentiable function from some closed interval [ a , b ] to U (Note that r is differentiable at the interval endpoints a and b.

To do this, r is defined on an interval that is larger than and includes [ a , b ].

), then by the multivariate chain rule , the composite function φ ∘ r is differentiable on [ a , b ] : d d t ( φ ∘ r ) ( t ) = ∇ φ ( r ( t ) ) ⋅ r ′ ( t ) {\displaystyle {\frac {\mathrm {d} }{\mathrm {d} t}}(\varphi \circ \mathbf {r} )(t)=\nabla \varphi (\mathbf {r} (t))\cdot \mathbf {r} '(t)} for all t in [ a , b ].

Here the ⋅ denotes the usual inner product.

Now suppose the domain U of φ contains the differentiable curve γ with endpoints p and q.

(This is oriented in the direction from p to q ).

If r parametrizes γ for t in [ a , b ] (i.

e.

, r represents γ as a function of t ), then ∫ γ ∇ φ ( r ) ⋅ d r = ∫ a b ∇ φ ( r ( t ) ) ⋅ r ′ ( t ) d t = ∫ a b d d t φ ( r ( t ) ) d t = φ ( r ( b ) ) − φ ( r ( a ) ) = φ ( q ) − φ ( p ) , {\displaystyle {\begin{aligned}\int _{\gamma }\nabla \varphi (\mathbf {r} )\cdot \mathrm {d} \mathbf {r} &=\int _{a}^{b}\nabla \varphi (\mathbf {r} (t))\cdot \mathbf {r} '(t)\mathrm {d} t\\&=\int _{a}^{b}{\frac {d}{dt}}\varphi (\mathbf {r} (t))\mathrm {d} t=\varphi (\mathbf {r} (b))-\varphi (\mathbf {r} (a))=\varphi \left(\mathbf {q} \right)-\varphi \left(\mathbf {p} \right),\end{aligned}}} where the definition of a line integral is used in the first equality, the above equation is used in the second equality, and the second fundamental theorem of calculus is used in the third equality.

[1] Even if the gradient theorem (also called fundamental theorem of calculus for line integrals ) has been proved for a differentiable (so looked as smooth) curve so far, the theorem is also proved for a piecewise-smooth curve since this curve is made by joining multiple differentiable curves so the proof for this curve is made by the proof per differentiable curve component.

[2] Examples [ edit ] Example 1 [ edit ] Suppose γ ⊂ R 2 is the circular arc oriented counterclockwise from (5, 0) to (−4, 3).

Using the definition of a line integral , ∫ γ y d x + x d y = ∫ 0 π − tan − 1 ( 3 4 ) ( ( 5 sin ⁡ t ) ( − 5 sin ⁡ t ) + ( 5 cos ⁡ t ) ( 5 cos ⁡ t ) ) d t = ∫ 0 π − tan − 1 ( 3 4 ) 25 ( − sin 2 ⁡ t + cos 2 ⁡ t ) d t = ∫ 0 π − tan − 1 ( 3 4 ) 25 cos ⁡ ( 2 t ) d t = 25 2 sin ⁡ ( 2 t ) | 0 π − tan − 1 ( 3 4 ) = 25 2 sin ⁡ ( 2 π − 2 tan − 1 ( 3 4 ) ) = − 25 2 sin ⁡ ( 2 tan − 1 ( 3 4 ) ) = − 25 ( 3 / 4 ) ( 3 / 4 ) 2 + 1 = − 12.

{\displaystyle {\begin{aligned}\int _{\gamma }y\,\mathrm {d} x+x\,\mathrm {d} y&=\int _{0}^{\pi -\tan ^{-1}\!\left({\frac {3}{4}}\right)}((5\sin t)(-5\sin t)+(5\cos t)(5\cos t))\,\mathrm {d} t\\&=\int _{0}^{\pi -\tan ^{-1}\!\left({\frac {3}{4}}\right)}25\left(-\sin ^{2}t+\cos ^{2}t\right)\mathrm {d} t\\&=\int _{0}^{\pi -\tan ^{-1}\!\left({\frac {3}{4}}\right)}25\cos(2t)\mathrm {d} t\ =\ \left.

{\tfrac {25}{2}}\sin(2t)\right|_{0}^{\pi -\tan ^{-1}\!\left({\tfrac {3}{4}}\right)}\\[.

5em]&={\tfrac {25}{2}}\sin \left(2\pi -2\tan ^{-1}\!\!\left({\tfrac {3}{4}}\right)\right)\\[.

5em]&=-{\tfrac {25}{2}}\sin \left(2\tan ^{-1}\!\!\left({\tfrac {3}{4}}\right)\right)\ =\ -{\frac {25(3/4)}{(3/4)^{2}+1}}=-12.

\end{aligned}}} This result can be obtained much more simply by noticing that the function f ( x , y ) = x y {\displaystyle f(x,y)=xy} has gradient ∇ f ( x , y ) = ( y , x ) {\displaystyle \nabla f(x,y)=(y,x)} , so by the Gradient Theorem: ∫ γ y d x + x d y = ∫ γ ∇ ( x y ) ⋅ ( d x , d y ) = x y | ( 5 , 0 ) ( − 4 , 3 ) = − 4 ⋅ 3 − 5 ⋅ 0 = − 12.

{\displaystyle \int _{\gamma }y\,\mathrm {d} x+x\,\mathrm {d} y=\int _{\gamma }\nabla (xy)\cdot (\mathrm {d} x,\mathrm {d} y)\ =\ xy\,|_{(5,0)}^{(-4,3)}=-4\cdot 3-5\cdot 0=-12.

} Example 2 [ edit ] For a more abstract example, suppose γ ⊂ R n has endpoints p , q , with orientation from p to q.

For u in R n , let | u | denote the Euclidean norm of u.

If α ≥ 1 is a real number, then ∫ γ | x | α − 1 x ⋅ d x = 1 α + 1 ∫ γ ( α + 1 ) | x | ( α + 1 ) − 2 x ⋅ d x = 1 α + 1 ∫ γ ∇ | x | α + 1 ⋅ d x = | q | α + 1 − | p | α + 1 α + 1 {\displaystyle {\begin{aligned}\int _{\gamma }|\mathbf {x} |^{\alpha -1}\mathbf {x} \cdot \mathrm {d} \mathbf {x} &={\frac {1}{\alpha +1}}\int _{\gamma }(\alpha +1)|\mathbf {x} |^{(\alpha +1)-2}\mathbf {x} \cdot \mathrm {d} \mathbf {x} \\&={\frac {1}{\alpha +1}}\int _{\gamma }\nabla |\mathbf {x} |^{\alpha +1}\cdot \mathrm {d} \mathbf {x} ={\frac {|\mathbf {q} |^{\alpha +1}-|\mathbf {p} |^{\alpha +1}}{\alpha +1}}\end{aligned}}} Here the final equality follows by the gradient theorem, since the function f ( x ) = | x | α +1 is differentiable on R n if α ≥ 1.

If α < 1 then this equality will still hold in most cases, but caution must be taken if γ passes through or encloses the origin, because the integrand vector field | x | α − 1 x will fail to be defined there.

However, the case α = −1 is somewhat different; in this case, the integrand becomes | x | −2 x = ∇(log | x |) , so that the final equality becomes log | q | − log | p |.

Note that if n = 1 , then this example is simply a slight variant of the familiar power rule from single-variable calculus.

Example 3 [ edit ] Suppose there are n point charges arranged in three-dimensional space, and the i -th point charge has charge Q i and is located at position p i in R 3.

We would like to calculate the work done on a particle of charge q as it travels from a point a to a point b in R 3.

Using Coulomb's law , we can easily determine that the force on the particle at position r will be F ( r ) = k q ∑ i = 1 n Q i ( r − p i ) | r − p i | 3 {\displaystyle \mathbf {F} (\mathbf {r} )=kq\sum _{i=1}^{n}{\frac {Q_{i}(\mathbf {r} -\mathbf {p} _{i})}{\left|\mathbf {r} -\mathbf {p} _{i}\right|^{3}}}} Here | u | denotes the Euclidean norm of the vector u in R 3 , and k = 1/(4 πε 0 ) , where ε 0 is the vacuum permittivity.

Let γ ⊂ R 3 − { p 1 ,.

, p n } be an arbitrary differentiable curve from a to b.

Then the work done on the particle is W = ∫ γ F ( r ) ⋅ d r = ∫ γ ( k q ∑ i = 1 n Q i ( r − p i ) | r − p i | 3 ) ⋅ d r = k q ∑ i = 1 n ( Q i ∫ γ r − p i | r − p i | 3 ⋅ d r ) {\displaystyle W=\int _{\gamma }\mathbf {F} (\mathbf {r} )\cdot \mathrm {d} \mathbf {r} =\int _{\gamma }\left(kq\sum _{i=1}^{n}{\frac {Q_{i}(\mathbf {r} -\mathbf {p} _{i})}{\left|\mathbf {r} -\mathbf {p} _{i}\right|^{3}}}\right)\cdot \mathrm {d} \mathbf {r} =kq\sum _{i=1}^{n}\left(Q_{i}\int _{\gamma }{\frac {\mathbf {r} -\mathbf {p} _{i}}{\left|\mathbf {r} -\mathbf {p} _{i}\right|^{3}}}\cdot \mathrm {d} \mathbf {r} \right)} Now for each i , direct computation shows that r − p i | r − p i | 3 = − ∇ 1 | r − p i |.

{\displaystyle {\frac {\mathbf {r} -\mathbf {p} _{i}}{\left|\mathbf {r} -\mathbf {p} _{i}\right|^{3}}}=-\nabla {\frac {1}{\left|\mathbf {r} -\mathbf {p} _{i}\right|}}.

} Thus, continuing from above and using the gradient theorem, W = − k q ∑ i = 1 n ( Q i ∫ γ ∇ 1 | r − p i | ⋅ d r ) = k q ∑ i = 1 n Q i ( 1 | a − p i | − 1 | b − p i | ) {\displaystyle W=-kq\sum _{i=1}^{n}\left(Q_{i}\int _{\gamma }\nabla {\frac {1}{\left|\mathbf {r} -\mathbf {p} _{i}\right|}}\cdot \mathrm {d} \mathbf {r} \right)=kq\sum _{i=1}^{n}Q_{i}\left({\frac {1}{\left|\mathbf {a} -\mathbf {p} _{i}\right|}}-{\frac {1}{\left|\mathbf {b} -\mathbf {p} _{i}\right|}}\right)} We are finished.

Of course, we could have easily completed this calculation using the powerful language of electrostatic potential or electrostatic potential energy (with the familiar formulas W = −Δ U = − q Δ V ).

However, we have not yet defined potential or potential energy, because the converse of the gradient theorem is required to prove that these are well-defined, differentiable functions and that these formulas hold ( see below ).

Thus, we have solved this problem using only Coulomb's Law, the definition of work, and the gradient theorem.

Converse of the gradient theorem [ edit ] The gradient theorem states that if the vector field F is the gradient of some scalar-valued function (i.

e.

, if F is conservative ), then F is a path-independent vector field (i.

e.

, the integral of F over some piecewise-differentiable curve is dependent only on end points).

This theorem has a powerful converse: Theorem — If F is a path-independent vector field, then F is the gradient of some scalar-valued function.

[3] It is straightforward to show that a vector field is path-independent if and only if the integral of the vector field over every closed loop in its domain is zero.

Thus the converse can alternatively be stated as follows: If the integral of F over every closed loop in the domain of F is zero, then F is the gradient of some scalar-valued function.

Proof of the converse [ edit ] Suppose U is an open , path-connected subset of R n , and F : U → R n is a continuous and path-independent vector field.

Fix some element a of U , and define f : U → R by f ( x ) := ∫ γ [ a , x ] F ( u ) ⋅ d u {\displaystyle f(\mathbf {x} ):=\int _{\gamma [\mathbf {a} ,\mathbf {x} ]}\mathbf {F} (\mathbf {u} )\cdot \mathrm {d} \mathbf {u} } Here γ [ a , x ] is any (differentiable) curve in U originating at a and terminating at x.

We know that f is well-defined because F is path-independent.

Let v be any nonzero vector in R n.

By the definition of the directional derivative , ∂ f ( x ) ∂ v = lim t → 0 f ( x + t v ) − f ( x ) t = lim t → 0 ∫ γ [ a , x + t v ] F ( u ) ⋅ d u − ∫ γ [ a , x ] F ( u ) ⋅ d u t = lim t → 0 1 t ∫ γ [ x , x + t v ] F ( u ) ⋅ d u {\displaystyle {\begin{aligned}{\frac {\partial f(\mathbf {x} )}{\partial \mathbf {v} }}&=\lim _{t\to 0}{\frac {f(\mathbf {x} +t\mathbf {v} )-f(\mathbf {x} )}{t}}\\&=\lim _{t\to 0}{\frac {\int _{\gamma [\mathbf {a} ,\mathbf {x} +t\mathbf {v} ]}\mathbf {F} (\mathbf {u} )\cdot \mathrm {d} \mathbf {u} -\int _{\gamma [\mathbf {a} ,\mathbf {x} ]}\mathbf {F} (\mathbf {u} )\cdot d\mathbf {u} }{t}}\\&=\lim _{t\to 0}{\frac {1}{t}}\int _{\gamma [\mathbf {x} ,\mathbf {x} +t\mathbf {v} ]}\mathbf {F} (\mathbf {u} )\cdot \mathrm {d} \mathbf {u} \end{aligned}}} To calculate the integral within the final limit, we must parametrize γ [ x , x + t v ].

Since F is path-independent, U is open, and t is approaching zero, we may assume that this path is a straight line, and parametrize it as u ( s ) = x + s v for 0 < s < t.

Now, since u' ( s ) = v , the limit becomes lim t → 0 1 t ∫ 0 t F ( u ( s ) ) ⋅ u ′ ( s ) d s = d d t ∫ 0 t F ( x + s v ) ⋅ v d s | t = 0 = F ( x ) ⋅ v {\displaystyle \lim _{t\to 0}{\frac {1}{t}}\int _{0}^{t}\mathbf {F} (\mathbf {u} (s))\cdot \mathbf {u} '(s)\,\mathrm {d} s={\frac {\mathrm {d} }{\mathrm {d} t}}\int _{0}^{t}\mathbf {F} (\mathbf {x} +s\mathbf {v} )\cdot \mathbf {v} \,\mathrm {d} s{\bigg |}_{t=0}=\mathbf {F} (\mathbf {x} )\cdot \mathbf {v} } where the first equality is from the definition of the derivative with a fact that the integral is equal to 0 at t = 0, and the second equality is from the first fundamental theorem of calculus.

Thus we have a formula for ∂ v f , (one of ways to represent the directional derivative ) where v is arbitrary; for f ( x ) := ∫ γ [ a , x ] F ( u ) ⋅ d u {\displaystyle f(\mathbf {x} ):=\int _{\gamma [\mathbf {a} ,\mathbf {x} ]}\mathbf {F} (\mathbf {u} )\cdot \mathrm {d} \mathbf {u} } (see its full definition above), its directional derivative with respect to v is ∂ f ( x ) ∂ v = ∂ v f ( x ) = D v f ( x ) = F ( x ) ⋅ v {\displaystyle {\frac {\partial f(\mathbf {x} )}{\partial \mathbf {v} }}=\partial _{\mathbf {v} }f(\mathbf {x} )=D_{\mathbf {v} }f(\mathbf {x} )=\mathbf {F} (\mathbf {x} )\cdot \mathbf {v} } where the first two equalities just show different representations of the directional derivative.

According to the definition of the gradient of a scalar function f , ∇ f ( x ) = F ( x ) {\displaystyle \nabla f(\mathbf {x} )=\mathbf {F} (\mathbf {x} )} , thus we have found a scalar-valued function f whose gradient is the path-independent vector field F (i.

e.

, F is a conservative vector field.

), as desired.

[3] Example of the converse principle [ edit ] Main article: Electric potential energy To illustrate the power of this converse principle, we cite an example that has significant physical consequences.

In classical electromagnetism , the electric force is a path-independent force; i.

e.

the work done on a particle that has returned to its original position within an electric field is zero (assuming that no changing magnetic fields are present).

Therefore, the above theorem implies that the electric force field F e : S → R 3 is conservative (here S is some open , path-connected subset of R 3 that contains a charge distribution).

Following the ideas of the above proof, we can set some reference point a in S , and define a function U e : S → R by U e ( r ) := − ∫ γ [ a , r ] F e ( u ) ⋅ d u {\displaystyle U_{e}(\mathbf {r} ):=-\int _{\gamma [\mathbf {a} ,\mathbf {r} ]}\mathbf {F} _{e}(\mathbf {u} )\cdot \mathrm {d} \mathbf {u} } Using the above proof, we know U e is well-defined and differentiable, and F e = −∇ U e (from this formula we can use the gradient theorem to easily derive the well-known formula for calculating work done by conservative forces: W = −Δ U ).

This function U e is often referred to as the electrostatic potential energy of the system of charges in S (with reference to the zero-of-potential a ).

In many cases, the domain S is assumed to be unbounded and the reference point a is taken to be "infinity", which can be made rigorous using limiting techniques.

This function U e is an indispensable tool used in the analysis of many physical systems.

Generalizations [ edit ] Main articles: Stokes' theorem and Closed and exact differential forms Many of the critical theorems of vector calculus generalize elegantly to statements about the integration of differential forms on manifolds.

In the language of differential forms and exterior derivatives , the gradient theorem states that ∫ ∂ γ ϕ = ∫ γ d ϕ {\displaystyle \int _{\partial \gamma }\phi =\int _{\gamma }\mathrm {d} \phi } for any 0-form , ϕ , defined on some differentiable curve γ ⊂ R n (here the integral of ϕ over the boundary of the γ is understood to be the evaluation of ϕ at the endpoints of γ ).

Notice the striking similarity between this statement and the generalized Stokes’ theorem , which says that the integral of any compactly supported differential form ω over the boundary of some orientable manifold Ω is equal to the integral of its exterior derivative d ω over the whole of Ω , i.

e.

, ∫ ∂ Ω ω = ∫ Ω d ω {\displaystyle \int _{\partial \Omega }\omega =\int _{\Omega }\mathrm {d} \omega } This powerful statement is a generalization of the gradient theorem from 1-forms defined on one-dimensional manifolds to differential forms defined on manifolds of arbitrary dimension.

The converse statement of the gradient theorem also has a powerful generalization in terms of differential forms on manifolds.

In particular, suppose ω is a form defined on a contractible domain , and the integral of ω over any closed manifold is zero.

Then there exists a form ψ such that ω = d ψ.

Thus, on a contractible domain, every closed form is exact.

This result is summarized by the Poincaré lemma.

See also [ edit ] State function Scalar potential Jordan curve theorem Differential of a function Classical mechanics Line integral § Path independence Conservative vector field § Path independence References [ edit ] ^ Williamson, Richard and Trotter, Hale.

(2004).

Multivariable Mathematics, Fourth Edition, p.

374.

Pearson Education, Inc.

^ Stewart, James (2021).

"16.

3 The Fundamental Theorem for Line Integrals".

Calculus (9th ed.

).

Cengage Learning.

pp.

1182–1185.

ISBN 978-1-337-62418-3.

^ a b "Williamson, Richard and Trotter, Hale.

(2004).

Multivariable Mathematics, Fourth Edition , p.

410.

Pearson Education, Inc.

" v t e Calculus Precalculus Binomial theorem Concave function Continuous function Factorial Finite difference Free variables and bound variables Graph of a function Linear function Radian Rolle's theorem Secant Slope Tangent Limits Indeterminate form Limit of a function One-sided limit Limit of a sequence Order of approximation (ε, δ)-definition of limit Differential calculus Derivative Second derivative Partial derivative Differential Differential operator Mean value theorem Notation Leibniz's notation Newton's notation Rules of differentiation linearity Power Sum Chain L'Hôpital's Product General Leibniz's rule Quotient Other techniques Implicit differentiation Inverse functions and differentiation Logarithmic derivative Related rates Stationary points First derivative test Second derivative test Extreme value theorem Maximum and minimum Further applications Newton's method Taylor's theorem Differential equation Ordinary differential equation Partial differential equation Stochastic differential equation Integral calculus Antiderivative Arc length Riemann integral Basic properties Constant of integration Fundamental theorem of calculus Differentiating under the integral sign Integration by parts Integration by substitution trigonometric Euler Tangent half-angle substitution Partial fractions in integration Quadratic integral Trapezoidal rule Volumes Washer method Shell method Integral equation Integro-differential equation Vector calculus Derivatives Curl Directional derivative Divergence Gradient Laplacian Basic theorems Line integrals Green's Stokes' Gauss' Multivariable calculus Divergence theorem Geometric Hessian matrix Jacobian matrix and determinant Lagrange multiplier Line integral Matrix Multiple integral Partial derivative Surface integral Volume integral Advanced topics Differential forms Exterior derivative Generalized Stokes' theorem Tensor calculus Sequences and series Arithmetico-geometric sequence Types of series Alternating Binomial Fourier Geometric Harmonic Infinite Power Maclaurin Taylor Telescoping Tests of convergence Abel's Alternating series Cauchy condensation Direct comparison Dirichlet's Integral Limit comparison Ratio Root Term Special functions and numbers Bernoulli numbers e (mathematical constant) Exponential function Natural logarithm Stirling's approximation History of calculus Adequality Brook Taylor Colin Maclaurin Generality of algebra Gottfried Wilhelm Leibniz Infinitesimal Infinitesimal calculus Isaac Newton Fluxion Law of Continuity Leonhard Euler Method of Fluxions The Method of Mechanical Theorems Lists Integrals rational functions irrational functions exponential functions logarithmic functions hyperbolic functions inverse trigonometric functions inverse Secant Secant cubed List of limits List of derivatives Miscellaneous topics Complex calculus Contour integral Differential geometry Manifold Curvature of curves of surfaces Tensor Euler–Maclaurin formula Gabriel's horn Integration Bee Proof that 22/7 exceeds π Regiomontanus' angle maximization problem Steinmetz solid Retrieved from " https://en.

wikipedia.

org/w/index.

php?title=Gradient_theorem&oldid=1217081265 " Category : Theorems in calculus Hidden categories: Articles with short description Short description is different from Wikidata Pages using sidebar with the child parameter Articles containing proofs This page was last edited on 3 April 2024, at 18:43 (UTC).

Text is available under the Creative Commons Attribution-ShareAlike License 4.

0 ; additional terms may apply.

By using this site, you agree to the Terms of Use and Privacy Policy.

Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc.

, a non-profit organization.

Privacy policy About Wikipedia Disclaimers Contact Wikipedia Code of Conduct Developers Statistics Cookie statement Mobile view.