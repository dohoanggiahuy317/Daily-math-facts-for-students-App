Derivative - Wikipedia Jump to content Main menu Main menu move to sidebar hide Navigation Main page Contents Current events Random article About Wikipedia Contact us Donate Contribute Help Learn to edit Community portal Recent changes Upload file Search Search Appearance Create account Log in Personal tools Create account Log in Pages for logged out editors learn more Contributions Talk Contents move to sidebar hide (Top) 1 Definition Toggle Definition subsection 1.

1 As a limit 1.

2 Using infinitesimals 2 Continuity and differentiability 3 Notation 4 Rules of computation Toggle Rules of computation subsection 4.

1 Rules for basic functions 4.

2 Rules for combined functions 4.

3 Computation example 5 Higher-order derivatives 6 In other dimensions Toggle In other dimensions subsection 6.

1 Vector-valued functions 6.

2 Partial derivatives 6.

3 Directional derivatives 6.

4 Total derivative, total differential and Jacobian matrix 7 Generalizations 8 See also 9 Notes 10 References 11 External links Toggle the table of contents Derivative 91 languages Afrikaans አማርኛ العربية Aragonés Asturianu Azərbaycanca تۆرکجه বাংলা Башҡортса Беларуская Беларуская (тарашкевіца) भोजपुरी Български Bosanski Català Чӑвашла Čeština Cymraeg Deutsch Eesti Ελληνικά Español Esperanto Euskara فارسی Français Furlan Gaeilge Galego 한국어 Հայերեն हिन्दी Hrvatski Ido Bahasa Indonesia Íslenska Italiano עברית ქართული ລາວ Latina Latviešu Lietuvių Lombard Magyar Македонски മലയാളം Malti मराठी Bahasa Melayu မြန်မာဘာသာ Nederlands 日本語 Norsk bokmål Norsk nynorsk Occitan Oromoo Oʻzbekcha / ўзбекча پنجابی Polski Português Qaraqalpaqsha Română Русский Scots Shqip Sicilianu Simple English Slovenčina Slovenščina Ślůnski کوردی Српски / srpski Srpskohrvatski / српскохрватски Suomi Svenska Tagalog தமிழ் Татарча / tatarça ไทย Türkçe Українська اردو Vèneto Tiếng Việt Walon 文言 吴语 ייִדיש 粵語 中文 Edit links Article Talk English Read View source View history Tools Tools move to sidebar hide Actions Read View source View history General What links here Related changes Upload file Special pages Permanent link Page information Cite this page Get shortened URL Download QR code Wikidata item Print/export Download as PDF Printable version Appearance move to sidebar hide From Wikipedia, the free encyclopedia (Redirected from Higher derivative ) Instantaneous rate of change (mathematics) For other uses, see Derivative (disambiguation).

Part of a series of articles about Calculus ∫ a b f ′ ( t ) d t = f ( b ) − f ( a ) {\displaystyle \int _{a}^{b}f'(t)\,dt=f(b)-f(a)} Fundamental theorem Limits Continuity Rolle's theorem Mean value theorem Inverse function theorem Differential Definitions Derivative ( generalizations ) Differential infinitesimal of a function total Concepts Differentiation notation Second derivative Implicit differentiation Logarithmic differentiation Related rates Taylor's theorem Rules and identities Sum Product Chain Power Quotient L'Hôpital's rule Inverse General Leibniz Faà di Bruno's formula Reynolds Integral Lists of integrals Integral transform Leibniz integral rule Definitions Antiderivative Integral ( improper ) Riemann integral Lebesgue integration Contour integration Integral of inverse functions Integration by Parts Discs Cylindrical shells Substitution ( trigonometric , tangent half-angle , Euler ) Euler's formula Partial fractions Changing order Reduction formulae Differentiating under the integral sign Risch algorithm Series Geometric ( arithmetico-geometric ) Harmonic Alternating Power Binomial Taylor Convergence tests Summand limit (term test) Ratio Root Integral Direct comparison Limit comparison Alternating series Cauchy condensation Dirichlet Abel Vector Gradient Divergence Curl Laplacian Directional derivative Identities Theorems Gradient Green's Stokes' Divergence generalized Stokes Helmholtz decomposition Multivariable Formalisms Matrix Tensor Exterior Geometric Definitions Partial derivative Multiple integral Line integral Surface integral Volume integral Jacobian Hessian Advanced Calculus on Euclidean space Generalized functions Limit of distributions Specialized Fractional Malliavin Stochastic Variations Miscellaneous Precalculus History Glossary List of topics Integration Bee Mathematical analysis Nonstandard analysis v t e The derivative is a fundamental tool of calculus that quantifies the sensitivity of change of a function 's output with respect to its input.

The derivative of a function of a single variable at a chosen input value, when it exists, is the slope of the tangent line to the graph of the function at that point.

The tangent line is the best linear approximation of the function near that input value.

For this reason, the derivative is often described as the instantaneous rate of change , the ratio of the instantaneous change in the dependent variable to that of the independent variable.

[1] The process of finding a derivative is called differentiation.

There are multiple different notations for differentiation, two of the most commonly used being Leibniz notation and prime notation.

Leibniz notation, named after Gottfried Wilhelm Leibniz , is represented as the ratio of two differentials , whereas prime notation is written by adding a prime mark.

Higher order notations represent repeated differentiation, and they are usually denoted in Leibniz notation by adding superscripts to the differentials, and in prime notation by adding additional prime marks.

The higher order derivatives can be applied in physics; for example, while the first derivative of the position of a moving object with respect to time is the object's velocity , how the position changes as time advances, the second derivative is the object's acceleration , how the velocity changes as time advances.

Derivatives can be generalized to functions of several real variables.

In this generalization, the derivative is reinterpreted as a linear transformation whose graph is (after an appropriate translation) the best linear approximation to the graph of the original function.

The Jacobian matrix is the matrix that represents this linear transformation with respect to the basis given by the choice of independent and dependent variables.

It can be calculated in terms of the partial derivatives with respect to the independent variables.

For a real-valued function of several variables, the Jacobian matrix reduces to the gradient vector.

Definition As a limit A function of a real variable f ( x ) {\displaystyle f(x)} is differentiable at a point a {\displaystyle a} of its domain , if its domain contains an open interval containing a {\displaystyle a} , and the limit L = lim h → 0 f ( a + h ) − f ( a ) h {\displaystyle L=\lim _{h\to 0}{\frac {f(a+h)-f(a)}{h}}} exists.

[2] This means that, for every positive real number ε {\displaystyle \varepsilon } , there exists a positive real number δ {\displaystyle \delta } such that, for every h {\displaystyle h} such that | h | < δ {\displaystyle |h|<\delta } and h ≠ 0 {\displaystyle h\neq 0} then f ( a + h ) {\displaystyle f(a+h)} is defined, and | L − f ( a + h ) − f ( a ) h | < ε , {\displaystyle \left|L-{\frac {f(a+h)-f(a)}{h}}\right|<\varepsilon ,} where the vertical bars denote the absolute value.

This is an example of the (ε, δ)-definition of limit.

[3] If the function f {\displaystyle f} is differentiable at a {\displaystyle a} , that is if the limit L {\displaystyle L} exists, then this limit is called the derivative of f {\displaystyle f} at a {\displaystyle a}.

Multiple notations for the derivative exist.

[4] The derivative of f {\displaystyle f} at a {\displaystyle a} can be denoted f ′ ( a ) {\displaystyle f'(a)} , read as " f {\displaystyle f} prime of a {\displaystyle a} "; or it can be denoted d f d x ( a ) {\textstyle {\frac {df}{dx}}(a)} , read as "the derivative of f {\displaystyle f} with respect to x {\displaystyle x} at a {\displaystyle a} " or " d f {\displaystyle df} by (or over) d x {\displaystyle dx} at a {\displaystyle a} ".

See § Notation below.

If f {\displaystyle f} is a function that has a derivative at every point in its domain , then a function can be defined by mapping every point x {\displaystyle x} to the value of the derivative of f {\displaystyle f} at x {\displaystyle x}.

This function is written f ′ {\displaystyle f'} and is called the derivative function or the derivative of f {\displaystyle f}.

The function f {\displaystyle f} sometimes has a derivative at most, but not all, points of its domain.

The function whose value at a {\displaystyle a} equals f ′ ( a ) {\displaystyle f'(a)} whenever f ′ ( a ) {\displaystyle f'(a)} is defined and elsewhere is undefined is also called the derivative of f {\displaystyle f}.

It is still a function, but its domain may be smaller than the domain of f {\displaystyle f}.

[5] For example, let f {\displaystyle f} be the squaring function: f ( x ) = x 2 {\displaystyle f(x)=x^{2}}.

Then the quotient in the definition of the derivative is [6] f ( a + h ) − f ( a ) h = ( a + h ) 2 − a 2 h = a 2 + 2 a h + h 2 − a 2 h = 2 a + h.

{\displaystyle {\frac {f(a+h)-f(a)}{h}}={\frac {(a+h)^{2}-a^{2}}{h}}={\frac {a^{2}+2ah+h^{2}-a^{2}}{h}}=2a+h.

} The division in the last step is valid as long as h ≠ 0 {\displaystyle h\neq 0}.

The closer h {\displaystyle h} is to 0 {\displaystyle 0} , the closer this expression becomes to the value 2 a {\displaystyle 2a}.

The limit exists, and for every input a {\displaystyle a} the limit is 2 a {\displaystyle 2a}.

So, the derivative of the squaring function is the doubling function: f ′ ( x ) = 2 x {\displaystyle f'(x)=2x}.

The graph of a function , drawn in black, and a tangent line to that graph, drawn in red.

The slope of the tangent line is equal to the derivative of the function at the marked point.

The derivative at different points of a differentiable function.

In this case, the derivative is equal to sin ⁡ ( x 2 ) + 2 x 2 cos ⁡ ( x 2 ) {\displaystyle \sin \left(x^{2}\right)+2x^{2}\cos \left(x^{2}\right)} The ratio in the definition of the derivative is the slope of the line through two points on the graph of the function f {\displaystyle f} , specifically the points ( a , f ( a ) ) {\displaystyle (a,f(a))} and ( a + h , f ( a + h ) ) {\displaystyle (a+h,f(a+h))}.

As h {\displaystyle h} is made smaller, these points grow closer together, and the slope of this line approaches the limiting value, the slope of the tangent to the graph of f {\displaystyle f} at a {\displaystyle a}.

In other words, the derivative is the slope of the tangent.

[7] Using infinitesimals One way to think of the derivative d f d x ( a ) {\textstyle {\frac {df}{dx}}(a)} is as the ratio of an infinitesimal change in the output of the function f {\displaystyle f} to an infinitesimal change in its input.

[8] In order to make this intuition rigorous, a system of rules for manipulating infinitesimal quantities is required.

[9] The system of hyperreal numbers is a way of treating infinite and infinitesimal quantities.

The hyperreals are an extension of the real numbers that contain numbers greater than anything of the form 1 + 1 + ⋯ + 1 {\displaystyle 1+1+\cdots +1} for any finite number of terms.

Such numbers are infinite, and their reciprocals are infinitesimals.

The application of hyperreal numbers to the foundations of calculus is called nonstandard analysis.

This provides a way to define the basic concepts of calculus such as the derivative and integral in terms of infinitesimals, thereby giving a precise meaning to the d {\displaystyle d} in the Leibniz notation.

Thus, the derivative of f ( x ) {\displaystyle f(x)} becomes f ′ ( x ) = st ⁡ ( f ( x + d x ) − f ( x ) d x ) {\displaystyle f'(x)=\operatorname {st} \left({\frac {f(x+dx)-f(x)}{dx}}\right)} for an arbitrary infinitesimal d x {\displaystyle dx} , where st {\displaystyle \operatorname {st} } denotes the standard part function , which "rounds off" each finite hyperreal to the nearest real.

[10] Taking the squaring function f ( x ) = x 2 {\displaystyle f(x)=x^{2}} as an example again, f ′ ( x ) = st ⁡ ( x 2 + 2 x ⋅ d x + ( d x ) 2 − x 2 d x ) = st ⁡ ( 2 x ⋅ d x + ( d x ) 2 d x ) = st ⁡ ( 2 x ⋅ d x d x + ( d x ) 2 d x ) = st ⁡ ( 2 x + d x ) = 2 x.

{\displaystyle {\begin{aligned}f'(x)&=\operatorname {st} \left({\frac {x^{2}+2x\cdot dx+(dx)^{2}-x^{2}}{dx}}\right)\\&=\operatorname {st} \left({\frac {2x\cdot dx+(dx)^{2}}{dx}}\right)\\&=\operatorname {st} \left({\frac {2x\cdot dx}{dx}}+{\frac {(dx)^{2}}{dx}}\right)\\&=\operatorname {st} \left(2x+dx\right)\\&=2x.

\end{aligned}}} Continuity and differentiability This function does not have a derivative at the marked point, as the function is not continuous there (specifically, it has a jump discontinuity ).

The absolute value function is continuous but fails to be differentiable at x = 0 since the tangent slopes do not approach the same value from the left as they do from the right.

If f {\displaystyle f} is differentiable at a {\displaystyle a} , then f {\displaystyle f} must also be continuous at a {\displaystyle a}.

[11] As an example, choose a point a {\displaystyle a} and let f {\displaystyle f} be the step function that returns the value 1 for all x {\displaystyle x} less than a {\displaystyle a} , and returns a different value 10 for all x {\displaystyle x} greater than or equal to a {\displaystyle a}.

The function f {\displaystyle f} cannot have a derivative at a {\displaystyle a}.

If h {\displaystyle h} is negative, then a + h {\displaystyle a+h} is on the low part of the step, so the secant line from a {\displaystyle a} to a + h {\displaystyle a+h} is very steep; as h {\displaystyle h} tends to zero, the slope tends to infinity.

If h {\displaystyle h} is positive, then a + h {\displaystyle a+h} is on the high part of the step, so the secant line from a {\displaystyle a} to a + h {\displaystyle a+h} has slope zero.

Consequently, the secant lines do not approach any single slope, so the limit of the difference quotient does not exist.

However, even if a function is continuous at a point, it may not be differentiable there.

For example, the absolute value function given by f ( x ) = | x | {\displaystyle f(x)=|x|} is continuous at x = 0 {\displaystyle x=0} , but it is not differentiable there.

If h {\displaystyle h} is positive, then the slope of the secant line from 0 to h {\displaystyle h} is one; if h {\displaystyle h} is negative, then the slope of the secant line from 0 {\displaystyle 0} to h {\displaystyle h} is − 1 {\displaystyle -1}.

[12] This can be seen graphically as a "kink" or a "cusp" in the graph at x = 0 {\displaystyle x=0}.

Even a function with a smooth graph is not differentiable at a point where its tangent is vertical : For instance, the function given by f ( x ) = x 1 / 3 {\displaystyle f(x)=x^{1/3}} is not differentiable at x = 0 {\displaystyle x=0}.

In summary, a function that has a derivative is continuous, but there are continuous functions that do not have a derivative.

[11] Most functions that occur in practice have derivatives at all points or almost every point.

Early in the history of calculus , many mathematicians assumed that a continuous function was differentiable at most points.

[13] Under mild conditions (for example, if the function is a monotone or a Lipschitz function ), this is true.

However, in 1872, Weierstrass found the first example of a function that is continuous everywhere but differentiable nowhere.

This example is now known as the Weierstrass function.

[14] In 1931, Stefan Banach proved that the set of functions that have a derivative at some point is a meager set in the space of all continuous functions.

Informally, this means that hardly any random continuous functions have a derivative at even one point.

[15] Notation Main article: Notation for differentiation One common symbol for the derivative of a function is Leibniz notation.

They are written as the quotient of two differentials d y {\displaystyle dy} and d x {\displaystyle dx} , [16] which were introduced by Gottfried Wilhelm Leibniz in 1675.

[17] It is still commonly used when the equation y = f ( x ) {\displaystyle y=f(x)} is viewed as a functional relationship between dependent and independent variables.

The first derivative is denoted by d y d x {\textstyle {\frac {dy}{dx}}} , read as "the derivative of y {\displaystyle y} with respect to x {\displaystyle x} ".

[18] This derivative can alternately be treated as the application of a differential operator to a function, d y d x = d d x f ( x ).

{\textstyle {\frac {dy}{dx}}={\frac {d}{dx}}f(x).

} Higher derivatives are expressed using the notation d n y d x n {\textstyle {\frac {d^{n}y}{dx^{n}}}} for the n {\displaystyle n} -th derivative of y = f ( x ) {\displaystyle y=f(x)}.

These are abbreviations for multiple applications of the derivative operator; for example, d 2 y d x 2 = d d x ( d d x f ( x ) ).

{\textstyle {\frac {d^{2}y}{dx^{2}}}={\frac {d}{dx}}{\Bigl (}{\frac {d}{dx}}f(x){\Bigr )}.

} [19] Unlike some alternatives, Leibniz notation involves explicit specification of the variable for differentiation, in the denominator, which removes ambiguity when working with multiple interrelated quantities.

The derivative of a composed function can be expressed using the chain rule : if u = g ( x ) {\displaystyle u=g(x)} and y = f ( g ( x ) ) {\displaystyle y=f(g(x))} then d y d x = d y d u ⋅ d u d x.

{\textstyle {\frac {dy}{dx}}={\frac {dy}{du}}\cdot {\frac {du}{dx}}.

} [20] Another common notation for differentiation is by using the prime mark in the symbol of a function f ( x ) {\displaystyle f(x)}.

This is known as prime notation , due to Joseph-Louis Lagrange.

[21] The first derivative is written as f ′ ( x ) {\displaystyle f'(x)} , read as " f {\displaystyle f} prime of x {\displaystyle x} ", or y ′ {\displaystyle y'} , read as " y {\displaystyle y} prime".

[22] Similarly, the second and the third derivatives can be written as f ″ {\displaystyle f''} and f ‴ {\displaystyle f'''} , respectively.

[23] For denoting the number of higher derivatives beyond this point, some authors use Roman numerals in superscript , whereas others place the number in parentheses, such as f i v {\displaystyle f^{\mathrm {iv} }} or f ( 4 ).

{\displaystyle f^{(4)}.

} [24] The latter notation generalizes to yield the notation f ( n ) {\displaystyle f^{(n)}} for the n {\displaystyle n} - th derivative of f {\displaystyle f}.

[19] In Newton's notation or the dot notation, a dot is placed over a symbol to represent a time derivative.

If y {\displaystyle y} is a function of t {\displaystyle t} , then the first and second derivatives can be written as y ˙ {\displaystyle {\dot {y}}} and y ¨ {\displaystyle {\ddot {y}}} , respectively.

This notation is used exclusively for derivatives with respect to time or arc length.

It is typically used in differential equations in physics and differential geometry.

[25] However, the dot notation becomes unmanageable for high-order derivatives (of order 4 or more) and cannot deal with multiple independent variables.

Another notation is D-notation , which represents the differential operator by the symbol D.

{\displaystyle D.

} [19] The first derivative is written D f ( x ) {\displaystyle Df(x)} and higher derivatives are written with a superscript, so the n {\displaystyle n} -th derivative is D n f ( x ).

{\displaystyle D^{n}f(x).

} This notation is sometimes called Euler notation , although it seems that Leonhard Euler did not use it, and the notation was introduced by Louis François Antoine Arbogast.

[26] To indicate a partial derivative, the variable differentiated by is indicated with a subscript, for example given the function u = f ( x , y ) , {\displaystyle u=f(x,y),} its partial derivative with respect to x {\displaystyle x} can be written D x u {\displaystyle D_{x}u} or D x f ( x , y ).

{\displaystyle D_{x}f(x,y).

} Higher partial derivatives can be indicated by superscripts or multiple subscripts, e.

g.

D x y f ( x , y ) = ∂ ∂ y ( ∂ ∂ x f ( x , y ) ) {\textstyle D_{xy}f(x,y)={\frac {\partial }{\partial y}}{\Bigl (}{\frac {\partial }{\partial x}}f(x,y){\Bigr )}} and D x 2 f ( x , y ) = ∂ ∂ x ( ∂ ∂ x f ( x , y ) ) {\textstyle D_{x}^{2}f(x,y)={\frac {\partial }{\partial x}}{\Bigl (}{\frac {\partial }{\partial x}}f(x,y){\Bigr )}}.

[27] Rules of computation Main article: Differentiation rules In principle, the derivative of a function can be computed from the definition by considering the difference quotient and computing its limit.

Once the derivatives of a few simple functions are known, the derivatives of other functions are more easily computed using rules for obtaining derivatives of more complicated functions from simpler ones.

This process of finding a derivative is known as differentiation.

[28] Rules for basic functions The following are the rules for the derivatives of the most common basic functions.

Here, a {\displaystyle a} is a real number, and e {\displaystyle e} is the mathematical constant approximately 2.

71828.

[29] Derivatives of powers : d d x x a = a x a − 1 {\displaystyle {\frac {d}{dx}}x^{a}=ax^{a-1}} Functions of exponential , natural logarithm , and logarithm with general base : d d x e x = e x {\displaystyle {\frac {d}{dx}}e^{x}=e^{x}} d d x a x = a x ln ⁡ ( a ) {\displaystyle {\frac {d}{dx}}a^{x}=a^{x}\ln(a)} , for a > 0 {\displaystyle a>0} d d x ln ⁡ ( x ) = 1 x {\displaystyle {\frac {d}{dx}}\ln(x)={\frac {1}{x}}} , for x > 0 {\displaystyle x>0} d d x log a ⁡ ( x ) = 1 x ln ⁡ ( a ) {\displaystyle {\frac {d}{dx}}\log _{a}(x)={\frac {1}{x\ln(a)}}} , for x , a > 0 {\displaystyle x,a>0} Trigonometric functions : d d x sin ⁡ ( x ) = cos ⁡ ( x ) {\displaystyle {\frac {d}{dx}}\sin(x)=\cos(x)} d d x cos ⁡ ( x ) = − sin ⁡ ( x ) {\displaystyle {\frac {d}{dx}}\cos(x)=-\sin(x)} d d x tan ⁡ ( x ) = sec 2 ⁡ ( x ) = 1 cos 2 ⁡ ( x ) = 1 + tan 2 ⁡ ( x ) {\displaystyle {\frac {d}{dx}}\tan(x)=\sec ^{2}(x)={\frac {1}{\cos ^{2}(x)}}=1+\tan ^{2}(x)} Inverse trigonometric functions : d d x arcsin ⁡ ( x ) = 1 1 − x 2 {\displaystyle {\frac {d}{dx}}\arcsin(x)={\frac {1}{\sqrt {1-x^{2}}}}} , for − 1 < x < 1 {\displaystyle -1<x<1} d d x arccos ⁡ ( x ) = − 1 1 − x 2 {\displaystyle {\frac {d}{dx}}\arccos(x)=-{\frac {1}{\sqrt {1-x^{2}}}}} , for − 1 < x < 1 {\displaystyle -1<x<1} d d x arctan ⁡ ( x ) = 1 1 + x 2 {\displaystyle {\frac {d}{dx}}\arctan(x)={\frac {1}{1+x^{2}}}} Rules for combined functions Given that the f {\displaystyle f} and g {\displaystyle g} are the functions.

The following are some of the most basic rules for deducing the derivative of functions from derivatives of basic functions.

[30] Constant rule : if f {\displaystyle f} is constant, then for all x {\displaystyle x} , f ′ ( x ) = 0.

{\displaystyle f'(x)=0.

} Sum rule : ( α f + β g ) ′ = α f ′ + β g ′ {\displaystyle (\alpha f+\beta g)'=\alpha f'+\beta g'} for all functions f {\displaystyle f} and g {\displaystyle g} and all real numbers α {\displaystyle \alpha } and β {\displaystyle \beta }.

Product rule : ( f g ) ′ = f ′ g + f g ′ {\displaystyle (fg)'=f'g+fg'} for all functions f {\displaystyle f} and g {\displaystyle g}.

As a special case, this rule includes the fact ( α f ) ′ = α f ′ {\displaystyle (\alpha f)'=\alpha f'} whenever α {\displaystyle \alpha } is a constant because α ′ f = 0 ⋅ f = 0 {\displaystyle \alpha 'f=0\cdot f=0} by the constant rule.

Quotient rule : ( f g ) ′ = f ′ g − f g ′ g 2 {\displaystyle \left({\frac {f}{g}}\right)'={\frac {f'g-fg'}{g^{2}}}} for all functions f {\displaystyle f} and g {\displaystyle g} at all inputs where g ≠ 0.

Chain rule for composite functions : If f ( x ) = h ( g ( x ) ) {\displaystyle f(x)=h(g(x))} , then f ′ ( x ) = h ′ ( g ( x ) ) ⋅ g ′ ( x ).

{\displaystyle f'(x)=h'(g(x))\cdot g'(x).

} Computation example The derivative of the function given by f ( x ) = x 4 + sin ⁡ ( x 2 ) − ln ⁡ ( x ) e x + 7 {\displaystyle f(x)=x^{4}+\sin \left(x^{2}\right)-\ln(x)e^{x}+7} is f ′ ( x ) = 4 x ( 4 − 1 ) + d ( x 2 ) d x cos ⁡ ( x 2 ) − d ( ln ⁡ x ) d x e x − ln ⁡ ( x ) d ( e x ) d x + 0 = 4 x 3 + 2 x cos ⁡ ( x 2 ) − 1 x e x − ln ⁡ ( x ) e x.

{\displaystyle {\begin{aligned}f'(x)&=4x^{(4-1)}+{\frac {d\left(x^{2}\right)}{dx}}\cos \left(x^{2}\right)-{\frac {d\left(\ln {x}\right)}{dx}}e^{x}-\ln(x){\frac {d\left(e^{x}\right)}{dx}}+0\\&=4x^{3}+2x\cos \left(x^{2}\right)-{\frac {1}{x}}e^{x}-\ln(x)e^{x}.

\end{aligned}}} Here the second term was computed using the chain rule and the third term using the product rule.

The known derivatives of the elementary functions x 2 {\displaystyle x^{2}} , x 4 {\displaystyle x^{4}} , sin ⁡ ( x ) {\displaystyle \sin(x)} , ln ⁡ ( x ) {\displaystyle \ln(x)} , and exp ⁡ ( x ) = e x {\displaystyle \exp(x)=e^{x}} , as well as the constant 7 {\displaystyle 7} , were also used.

Higher-order derivatives Higher order derivatives means that a function is differentiated repeatedly.

Given that f {\displaystyle f} is a differentiable function, the derivative of f {\displaystyle f} is the first derivative, denoted as f ′ {\displaystyle f'}.

The derivative of f ′ {\displaystyle f'} is the second derivative , denoted as f ″ {\displaystyle f''} , and the derivative of f ″ {\displaystyle f''} is the third derivative , denoted as f ‴ {\displaystyle f'''}.

By continuing this process, if it exists, the n {\displaystyle n} - th derivative as the derivative of the ( n − 1 ) {\displaystyle (n-1)} - th derivative or the derivative of order n {\displaystyle n}.

As has been discussed above , the generalization of derivative of a function f {\displaystyle f} may be denoted as f ( n ) {\displaystyle f^{(n)}}.

[31] A function that has k {\displaystyle k} successive derivatives is called k {\displaystyle k} times differentiable.

If the k {\displaystyle k} - th derivative is continuous, then the function is said to be of differentiability class C k {\displaystyle C^{k}}.

[32] A function that has infinitely many derivatives is called infinitely differentiable or smooth.

[33] One example of the infinitely differentiable function is polynomial ; differentiate this function repeatedly results the constant function , and the infinitely subsequent derivative of that function are all zero.

[34] In one of its applications , the higher-order derivatives may have specific interpretations in physics.

Suppose that a function represents the position of an object at the time.

The first derivative of that function is the velocity of an object with respect to time, the second derivative of the function is the acceleration of an object with respect to time, [28] and the third derivative is the jerk.

[35] In other dimensions See also: Vector calculus and Multivariable calculus Vector-valued functions A vector-valued function y {\displaystyle \mathbf {y} } of a real variable sends real numbers to vectors in some vector space R n {\displaystyle \mathbb {R} ^{n}}.

A vector-valued function can be split up into its coordinate functions y 1 ( t ) , y 2 ( t ) , … , y n ( t ) {\displaystyle y_{1}(t),y_{2}(t),\dots ,y_{n}(t)} , meaning that y = ( y 1 ( t ) , y 2 ( t ) , … , y n ( t ) ) {\displaystyle \mathbf {y} =(y_{1}(t),y_{2}(t),\dots ,y_{n}(t))}.

This includes, for example, parametric curves in R 2 {\displaystyle \mathbb {R} ^{2}} or R 3 {\displaystyle \mathbb {R} ^{3}}.

The coordinate functions are real-valued functions, so the above definition of derivative applies to them.

The derivative of y ( t ) {\displaystyle \mathbf {y} (t)} is defined to be the vector , called the tangent vector , whose coordinates are the derivatives of the coordinate functions.

That is, [36] y ′ ( t ) = lim h → 0 y ( t + h ) − y ( t ) h , {\displaystyle \mathbf {y} '(t)=\lim _{h\to 0}{\frac {\mathbf {y} (t+h)-\mathbf {y} (t)}{h}},} if the limit exists.

The subtraction in the numerator is the subtraction of vectors, not scalars.

If the derivative of y {\displaystyle \mathbf {y} } exists for every value of t {\displaystyle t} , then y {\displaystyle \mathbf {y} } is another vector-valued function.

[36] Partial derivatives Main article: Partial derivative Functions can depend upon more than one variable.

A partial derivative of a function of several variables is its derivative with respect to one of those variables, with the others held constant.

Partial derivatives are used in vector calculus and differential geometry.

As with ordinary derivatives, multiple notations exist: the partial derivative of a function f ( x , y , … ) {\displaystyle f(x,y,\dots )} with respect to the variable x {\displaystyle x} is variously denoted by f x {\displaystyle f_{x}} , f x ′ {\displaystyle f'_{x}} , ∂ x f {\displaystyle \partial _{x}f} , ∂ ∂ x f {\displaystyle {\frac {\partial }{\partial x}}f} , or ∂ f ∂ x {\displaystyle {\frac {\partial f}{\partial x}}} , among other possibilities.

[37] It can be thought of as the rate of change of the function in the x {\displaystyle x} -direction.

[38] Here ∂ is a rounded d called the partial derivative symbol.

To distinguish it from the letter d , ∂ is sometimes pronounced "der", "del", or "partial" instead of "dee".

[39] For example, let f ( x , y ) = x 2 + x y + y 2 {\displaystyle f(x,y)=x^{2}+xy+y^{2}} , then the partial derivative of function f {\displaystyle f} with respect to both variables x {\displaystyle x} and y {\displaystyle y} are, respectively: ∂ f ∂ x = 2 x + y , ∂ f ∂ y = x + 2 y.

{\displaystyle {\frac {\partial f}{\partial x}}=2x+y,\qquad {\frac {\partial f}{\partial y}}=x+2y.

} In general, the partial derivative of a function f ( x 1 , … , x n ) {\displaystyle f(x_{1},\dots ,x_{n})} in the direction x i {\displaystyle x_{i}} at the point ( a 1 , … , a n ) {\displaystyle (a_{1},\dots ,a_{n})} is defined to be: [40] ∂ f ∂ x i ( a 1 , … , a n ) = lim h → 0 f ( a 1 , … , a i + h , … , a n ) − f ( a 1 , … , a i , … , a n ) h.

{\displaystyle {\frac {\partial f}{\partial x_{i}}}(a_{1},\ldots ,a_{n})=\lim _{h\to 0}{\frac {f(a_{1},\ldots ,a_{i}+h,\ldots ,a_{n})-f(a_{1},\ldots ,a_{i},\ldots ,a_{n})}{h}}.

} This is fundamental for the study of the functions of several real variables.

Let f ( x 1 , … , x n ) {\displaystyle f(x_{1},\dots ,x_{n})} be such a real-valued function.

If all partial derivatives f {\displaystyle f} with respect to x j {\displaystyle x_{j}} are defined at the point ( a 1 , … , a n ) {\displaystyle (a_{1},\dots ,a_{n})} , these partial derivatives define the vector ∇ f ( a 1 , … , a n ) = ( ∂ f ∂ x 1 ( a 1 , … , a n ) , … , ∂ f ∂ x n ( a 1 , … , a n ) ) , {\displaystyle \nabla f(a_{1},\ldots ,a_{n})=\left({\frac {\partial f}{\partial x_{1}}}(a_{1},\ldots ,a_{n}),\ldots ,{\frac {\partial f}{\partial x_{n}}}(a_{1},\ldots ,a_{n})\right),} which is called the gradient of f {\displaystyle f} at a {\displaystyle a}.

If f {\displaystyle f} is differentiable at every point in some domain, then the gradient is a vector-valued function ∇ f {\displaystyle \nabla f} that maps the point ( a 1 , … , a n ) {\displaystyle (a_{1},\dots ,a_{n})} to the vector ∇ f ( a 1 , … , a n ) {\displaystyle \nabla f(a_{1},\dots ,a_{n})}.

Consequently, the gradient determines a vector field.

[41] Directional derivatives Main article: Directional derivative If f {\displaystyle f} is a real-valued function on R n {\displaystyle \mathbb {R} ^{n}} , then the partial derivatives of f {\displaystyle f} measure its variation in the direction of the coordinate axes.

For example, if f {\displaystyle f} is a function of x {\displaystyle x} and y {\displaystyle y} , then its partial derivatives measure the variation in f {\displaystyle f} in the x {\displaystyle x} and y {\displaystyle y} direction.

However, they do not directly measure the variation of f {\displaystyle f} in any other direction, such as along the diagonal line y = x {\displaystyle y=x}.

These are measured using directional derivatives.

Choose a vector v = ( v 1 , … , v n ) {\displaystyle \mathbf {v} =(v_{1},\ldots ,v_{n})} , then the directional derivative of f {\displaystyle f} in the direction of v {\displaystyle \mathbf {v} } at the point x {\displaystyle \mathbf {x} } is: [42] D v f ( x ) = lim h → 0 f ( x + h v ) − f ( x ) h.

{\displaystyle D_{\mathbf {v} }{f}(\mathbf {x} )=\lim _{h\rightarrow 0}{\frac {f(\mathbf {x} +h\mathbf {v} )-f(\mathbf {x} )}{h}}.

} If all the partial derivatives of f {\displaystyle f} exist and are continuous at x {\displaystyle \mathbf {x} } , then they determine the directional derivative of f {\displaystyle f} in the direction v {\displaystyle \mathbf {v} } by the formula: [43] D v f ( x ) = ∑ j = 1 n v j ∂ f ∂ x j.

{\displaystyle D_{\mathbf {v} }{f}(\mathbf {x} )=\sum _{j=1}^{n}v_{j}{\frac {\partial f}{\partial x_{j}}}.

} Total derivative, total differential and Jacobian matrix Main article: Total derivative When f {\displaystyle f} is a function from an open subset of R n {\displaystyle \mathbb {R} ^{n}} to R m {\displaystyle \mathbb {R} ^{m}} , then the directional derivative of f {\displaystyle f} in a chosen direction is the best linear approximation to f {\displaystyle f} at that point and in that direction.

However, when n > 1 {\displaystyle n>1} , no single directional derivative can give a complete picture of the behavior of f {\displaystyle f}.

The total derivative gives a complete picture by considering all directions at once.

That is, for any vector v {\displaystyle \mathbf {v} } starting at a {\displaystyle \mathbf {a} } , the linear approximation formula holds: [44] f ( a + v ) ≈ f ( a ) + f ′ ( a ) v.

{\displaystyle f(\mathbf {a} +\mathbf {v} )\approx f(\mathbf {a} )+f'(\mathbf {a} )\mathbf {v}.

} Similarly with the single-variable derivative, f ′ ( a ) {\displaystyle f'(\mathbf {a} )} is chosen so that the error in this approximation is as small as possible.

The total derivative of f {\displaystyle f} at a {\displaystyle \mathbf {a} } is the unique linear transformation f ′ ( a ) : R n → R m {\displaystyle f'(\mathbf {a} )\colon \mathbb {R} ^{n}\to \mathbb {R} ^{m}} such that [44] lim h → 0 ‖ f ( a + h ) − ( f ( a ) + f ′ ( a ) h ) ‖ ‖ h ‖ = 0.

{\displaystyle \lim _{\mathbf {h} \to 0}{\frac {\lVert f(\mathbf {a} +\mathbf {h} )-(f(\mathbf {a} )+f'(\mathbf {a} )\mathbf {h} )\rVert }{\lVert \mathbf {h} \rVert }}=0.

} Here h {\displaystyle \mathbf {h} } is a vector in R n {\displaystyle \mathbb {R} ^{n}} , so the norm in the denominator is the standard length on R n {\displaystyle \mathbb {R} ^{n}}.

However, f ′ ( a ) h {\displaystyle f'(\mathbf {a} )\mathbf {h} } is a vector in R m {\displaystyle \mathbb {R} ^{m}} , and the norm in the numerator is the standard length on R m {\displaystyle \mathbb {R} ^{m}}.

[44] If v {\displaystyle v} is a vector starting at a {\displaystyle a} , then f ′ ( a ) v {\displaystyle f'(\mathbf {a} )\mathbf {v} } is called the pushforward of v {\displaystyle \mathbf {v} } by f {\displaystyle f}.

[45] If the total derivative exists at a {\displaystyle \mathbf {a} } , then all the partial derivatives and directional derivatives of f {\displaystyle f} exist at a {\displaystyle \mathbf {a} } , and for all v {\displaystyle \mathbf {v} } , f ′ ( a ) v {\displaystyle f'(\mathbf {a} )\mathbf {v} } is the directional derivative of f {\displaystyle f} in the direction v {\displaystyle \mathbf {v} }.

If f {\displaystyle f} is written using coordinate functions, so that f = ( f 1 , f 2 , … , f m ) {\displaystyle f=(f_{1},f_{2},\dots ,f_{m})} , then the total derivative can be expressed using the partial derivatives as a matrix.

This matrix is called the Jacobian matrix of f {\displaystyle f} at a {\displaystyle \mathbf {a} } : [46] f ′ ( a ) = Jac a = ( ∂ f i ∂ x j ) i j.

{\displaystyle f'(\mathbf {a} )=\operatorname {Jac} _{\mathbf {a} }=\left({\frac {\partial f_{i}}{\partial x_{j}}}\right)_{ij}.

} Generalizations Main article: Generalizations of the derivative The concept of a derivative can be extended to many other settings.

The common thread is that the derivative of a function at a point serves as a linear approximation of the function at that point.

An important generalization of the derivative concerns complex functions of complex variables , such as functions from (a domain in) the complex numbers C {\displaystyle \mathbb {C} } to C {\displaystyle \mathbb {C} }.

The notion of the derivative of such a function is obtained by replacing real variables with complex variables in the definition.

[47] If C {\displaystyle \mathbb {C} } is identified with R 2 {\displaystyle \mathbb {R} ^{2}} by writing a complex number z {\displaystyle z} as x + i y {\displaystyle x+iy} , then a differentiable function from C {\displaystyle \mathbb {C} } to C {\displaystyle \mathbb {C} } is certainly differentiable as a function from R 2 {\displaystyle \mathbb {R} ^{2}} to R 2 {\displaystyle \mathbb {R} ^{2}} (in the sense that its partial derivatives all exist), but the converse is not true in general: the complex derivative only exists if the real derivative is complex linear and this imposes relations between the partial derivatives called the Cauchy–Riemann equations – see holomorphic functions.

[48] Another generalization concerns functions between differentiable or smooth manifolds.

Intuitively speaking such a manifold M {\displaystyle M} is a space that can be approximated near each point x {\displaystyle x} by a vector space called its tangent space : the prototypical example is a smooth surface in R 3 {\displaystyle \mathbb {R} ^{3}}.

The derivative (or differential) of a (differentiable) map f : M → N {\displaystyle f:M\to N} between manifolds, at a point x {\displaystyle x} in M {\displaystyle M} , is then a linear map from the tangent space of M {\displaystyle M} at x {\displaystyle x} to the tangent space of N {\displaystyle N} at f ( x ) {\displaystyle f(x)}.

The derivative function becomes a map between the tangent bundles of M {\displaystyle M} and N {\displaystyle N}.

This definition is used in differential geometry.

[49] Differentiation can also be defined for maps between vector space , such as Banach space , in which those generalizations are the Gateaux derivative and the Fréchet derivative.

[50] One deficiency of the classical derivative is that very many functions are not differentiable.

Nevertheless, there is a way of extending the notion of the derivative so that all continuous functions and many other functions can be differentiated using a concept known as the weak derivative.

The idea is to embed the continuous functions in a larger space called the space of distributions and only require that a function is differentiable "on average".

[51] Properties of the derivative have inspired the introduction and study of many similar objects in algebra and topology; an example is differential algebra.

Here, it consists of the derivation of some topics in abstract algebra, such as rings , ideals , field , and so on.

[52] The discrete equivalent of differentiation is finite differences.

The study of differential calculus is unified with the calculus of finite differences in time scale calculus.

[53] The arithmetic derivative involves the function that is defined for the integers by the prime factorization.

This is an analogy with the product rule.

[54] See also Integral Notes ^ Stewart 2002 , p.

129–130.

^ Stewart 2002 , p.

127; Strang et al.

2023 , p.

220.

^ Gonick 2012 , p.

83.

^ Gonick 2012 , p.

88; Strang et al.

2023 , p.

234.

^ Gonick 2012 , p.

83; Strang et al.

2023 , p.

232.

^ Gonick 2012 , pp.

77–80.

^ Thompson 1998 , pp.

34, 104; Stewart 2002 , p.

128.

^ Thompson 1998 , pp.

84–85.

^ Keisler 2012 , pp.

902–904.

^ Keisler 2012 , p.

45; Henle & Kleinberg 2003 , p.

66.

^ a b Gonick 2012 , p.

156.

^ Gonick 2012 , p.

149.

^ Jašek 1922 ; Jarník 1922 ; Rychlík 1923.

^ David 2018.

^ Banach 1931 , cited in Hewitt & Stromberg 1965.

^ Apostol 1967 , p.

172.

^ Cajori 2007 , p.

204.

^ Moore & Siegel 2013 , p.

110.

^ a b c Varberg, Purcell & Rigdon 2007 , p.

125–126.

^ In the formulation of calculus in terms of limits, various authors have assigned the d u {\displaystyle du} symbol various meanings.

Some authors such as Varberg, Purcell & Rigdon 2007 , p.

119 and Stewart 2002 , p.

177 do not assign a meaning to d u {\displaystyle du} by itself, but only as part of the symbol d u d x {\textstyle {\frac {du}{dx}}}.

Others define d x {\displaystyle dx} as an independent variable, and define d u {\displaystyle du} by d u = d x f ′ ( x ).

{\displaystyle du=dxf'(x).

} In non-standard analysis d u {\displaystyle du} is defined as an infinitesimal.

It is also interpreted as the exterior derivative of a function u {\displaystyle u}.

See differential (infinitesimal) for further information.

^ Schwartzman 1994 , p.

171.

^ Moore & Siegel 2013 , p.

110; Goodman 1963 , p.

78–79.

^ Varberg, Purcell & Rigdon 2007 , p.

125–126; Cajori 2007 , p.

228.

^ Choudary & Niculescu 2014 , p.

222 ; Apostol 1967 , p.

171.

^ Evans 1999 , p.

63; Kreyszig 1991 , p.

1.

^ Cajori 1923.

^ Apostol 1967 , p.

172; Varberg, Purcell & Rigdon 2007 , p.

125–126.

^ a b Apostol 1967 , p.

160.

^ Varberg, Purcell & Rigdon 2007.

See p.

133 for the power rule, p.

115–116 for the trigonometric functions, p.

326 for the natural logarithm, p.

338–339 for exponential with base e {\displaystyle e} , p.

343 for the exponential with base a {\displaystyle a} , p.

344 for the logarithm with base a {\displaystyle a} , and p.

369 for the inverse of trigonometric functions.

^ For constant rule and sum rule, see Apostol 1967 , p.

161, 164, respectively.

For the product rule, quotient rule, and chain rule, see Varberg, Purcell & Rigdon 2007 , p.

111–112, 119, respectively.

For the special case of the product rule, that is, the product of a constant and a function, see Varberg, Purcell & Rigdon 2007 , p.

108–109.

^ Apostol 1967 , p.

160; Varberg, Purcell & Rigdon 2007 , p.

125–126.

^ Warner 1983 , p.

5.

^ Debnath & Shah 2015 , p.

40.

^ Carothers 2000 , p.

176.

^ Stewart 2002 , p.

193.

^ a b Stewart 2002 , p.

893.

^ Stewart 2002 , p.

947 ; Christopher 2013 , p.

682.

^ Stewart 2002 , p.

949.

^ Silverman 1989 , p.

216 ; Bhardwaj 2005 , See p.

6.

4.

^ Mathai & Haubold 2017 , p.

52.

^ Gbur 2011 , pp.

36–37.

^ Varberg, Purcell & Rigdon 2007 , p.

642.

^ Guzman 2003 , p.

35.

^ a b c Davvaz 2023 , p.

266.

^ Lee 2013 , p.

72.

^ Davvaz 2023 , p.

267.

^ Roussos 2014 , p.

303.

^ Gbur 2011 , pp.

261–264.

^ Gray, Abbena & Salamon 2006 , p.

826.

^ Azegami 2020.

See p.

209 for the Gateaux derivative, and p.

211 for the Fréchet derivative.

^ Funaro 1992 , p.

84–85.

^ Kolchin 1973 , p.

58 , 126.

^ Georgiev 2018 , p.

8.

^ Barbeau 1961.

References Apostol, Tom M.

(June 1967), Calculus, Vol.

1: One-Variable Calculus with an Introduction to Linear Algebra , vol.

1 (2nd ed.

), Wiley, ISBN 978-0-471-00005-1 Azegami, Hideyuki (2020), Shape Optimization Problems , Springer Optimization and Its Applications, vol.

164, Springer, doi : 10.

1007/978-981-15-7618-8 , ISBN 978-981-15-7618-8 , S2CID 226442409 Banach, Stefan (1931), "Uber die Baire'sche Kategorie gewisser Funktionenmengen" , Studia Math.

, 3 (3): 174–179, doi : 10.

4064/sm-3-1-174-179.

Barbeau, E.

J.

(1961).

"Remarks on an arithmetic derivative".

Canadian Mathematical Bulletin.

4 (2): 117–122.

doi : 10.

4153/CMB-1961-013-0.

Zbl 0101.

03702.

Bhardwaj, R.

S.

(2005), Mathematics for Economics & Business (2nd ed.

), Excel Books India, ISBN 9788174464507 Cajori, Florian (1923), "The History of Notations of the Calculus", Annals of Mathematics , 25 (1): 1–46, doi : 10.

2307/1967725 , hdl : 2027/mdp.

39015017345896 , JSTOR 1967725 Cajori, Florian (2007), A History of Mathematical Notations , vol.

2, Cosimo Classics, ISBN 978-1-60206-713-4 Carothers, N.

L.

(2000), Real Analysis , Cambridge University Press Choudary, A.

D.

R.

; Niculescu, Constantin P.

(2014), Real Analysis on Intervals , Springer India, doi : 10.

1007/978-81-322-2148-7 , ISBN 978-81-322-2148-7 Christopher, Essex (2013), Calculus: A complete course , Pearson, p.

682, ISBN 9780321781079 , OCLC 872345701 Courant, Richard ; John, Fritz (December 22, 1998), Introduction to Calculus and Analysis, Vol.

1 , Springer-Verlag , doi : 10.

1007/978-1-4613-8955-2 , ISBN 978-3-540-65058-4 David, Claire (2018), "Bypassing dynamical systems: A simple way to get the box-counting dimension of the graph of the Weierstrass function", Proceedings of the International Geometry Center , 11 (2), Academy of Sciences of Ukraine: 53–68, arXiv : 1711.

10349 , doi : 10.

15673/tmgc.

v11i2.

1028 Davvaz, Bijan (2023), Vectors and Functions of Several Variables , Springer, doi : 10.

1007/978-981-99-2935-1 , ISBN 978-981-99-2935-1 , S2CID 259885793 Debnath, Lokenath; Shah, Firdous Ahmad (2015), Wavelet Transforms and Their Applications (2nd ed.

), Birkhäuser, doi : 10.

1007/978-0-8176-8418-1 , ISBN 978-0-8176-8418-1 Evans, Lawrence (1999), Partial Differential Equations , American Mathematical Society, ISBN 0-8218-0772-2 Eves, Howard (January 2, 1990), An Introduction to the History of Mathematics (6th ed.

), Brooks Cole, ISBN 978-0-03-029558-4 Funaro, Daniele (1992), Polynomial Approximation of Differential Equations , Lecture Notes in Physics Monographs, vol.

8, Springer, doi : 10.

1007/978-3-540-46783-0 , ISBN 978-3-540-46783-0 Gbur, Greg (2011), Mathematical Methods for Optical Physics and Engineering , Cambridge University Press, Bibcode : 2011mmop.

book.

G , ISBN 978-1-139-49269-0 Georgiev, Svetlin G.

(2018), Fractional Dynamic Calculus and Fractional Dynamic Equations on Time Scales , Springer, doi : 10.

1007/978-3-319-73954-0 , ISBN 978-3-319-73954-0 Goodman, A.

W.

(1963), Analytic Geometry and the Calculus , The MacMillan Company Gonick, Larry (2012), The Cartoon Guide to Calculus , William Morrow, ISBN 978-0-06-168909-3 Gray, Alfred; Abbena, Elsa; Salamon, Simon (2006), Modern Differential Geometry of Curves and Surfaces with Mathematica , CRC Press, ISBN 978-1-58488-448-4 Guzman, Alberto (2003), Derivatives and Integrals of Multivariable Functions , Springer, doi : 10.

1007/978-1-4612-0035-2 , ISBN 978-1-4612-0035-2 Henle, James M.

; Kleinberg, Eugene M.

(2003), Infinitesimal Calculus , Dover Publications, ISBN 978-0-486-42886-4 Hewitt, Edwin ; Stromberg, Karl R.

(1965), Real and abstract analysis , Springer-Verlag, Theorem 17.

8, doi : 10.

1007/978-3-662-29794-0 , ISBN 978-3-662-28275-5 Jašek, Martin (1922), "Funkce Bolzanova" (PDF) , Časopis pro Pěstování Matematiky a Fyziky (in Czech), 51 (2): 69–76, doi : 10.

21136/CPMF.

1922.

121916 Jarník, Vojtěch (1922), "O funkci Bolzanově" (PDF) , Časopis pro Pěstování Matematiky a Fyziky (in Czech), 51 (4): 248–264, doi : 10.

21136/CPMF.

1922.

109021.

See the English version here.

Keisler, H.

Jerome (2012) [1986], Elementary Calculus: An Approach Using Infinitesimals (2nd ed.

), Prindle, Weber & Schmidt, ISBN 978-0-871-50911-6 Kolchin, Ellis (1973), Differential Algebra And Algebraic Groups , Academic Press, ISBN 978-0-08-087369-5 Kreyszig, Erwin (1991), Differential Geometry , New York: Dover , ISBN 0-486-66721-9 Larson, Ron; Hostetler, Robert P.

; Edwards, Bruce H.

(February 28, 2006), Calculus: Early Transcendental Functions (4th ed.

), Houghton Mifflin Company, ISBN 978-0-618-60624-5 Lee, John M.

(2013), Introduction to Smooth Manifolds , Graduate Texts in Mathematics, vol.

218, Springer, doi : 10.

1007/978-0-387-21752-9 , ISBN 978-0-387-21752-9 Mathai, A.

M.

; Haubold, H.

J.

(2017), Fractional and Multivariable Calculus: Model Building and Optimization Problems , Springer, doi : 10.

1007/978-3-319-59993-9 , ISBN 978-3-319-59993-9 Moore, Will H.

; Siegel, David A.

(2013), A Mathematical Course for Political and Social Research , Princeton University Press, ISBN 978-0-691-15995-9 Roussos, Ioannis M.

(2014), Improper Riemann Integral , CRC Press , ISBN 978-1-4665-8807-3 Rychlík, Karel (1923), Über eine Funktion aus Bolzanos handschriftlichem Nachlasse Schwartzman, Steven (1994), The Words of Mathematics: An Etymological Dictionary of Mathematical Terms Used in English , Mathematical Association of American, ISBN 9781614445012 Silverman, Richard A.

(1989), Essential Calculus: With Applications , Courier Corporation, ISBN 9780486660974 Stewart, James (December 24, 2002), Calculus (5th ed.

), Brooks Cole, ISBN 978-0-534-39339-7 Strang, Gilbert ; et al.

(2023), Calculus, volume 1 , OpenStax, ISBN 978-1-947172-13-5 Thompson, Silvanus P.

(September 8, 1998), Calculus Made Easy (Revised, Updated, Expanded ed.

), New York: St.

Martin's Press, ISBN 978-0-312-18548-0 Varberg, Dale E.

; Purcell, Edwin J.

; Rigdon, Steven E.

(2007), Calculus (9th ed.

), Pearson Prentice Hall , ISBN 978-0131469686 Warner, Frank W.

(1983), Foundations of Differentiable Manifolds and Lie Groups , Springer, ISBN 978-0-387-90894-6 External links Differentiation at Wikipedia's sister projects Definitions from Wiktionary Textbooks from Wikibooks Resources from Wikiversity "Derivative" , Encyclopedia of Mathematics , EMS Press , 2001 [1994] Khan Academy : "Newton, Leibniz, and Usain Bolt" Weisstein, Eric W.

"Derivative".

MathWorld.

Online Derivative Calculator from Wolfram Alpha.

v t e Calculus Precalculus Binomial theorem Concave function Continuous function Factorial Finite difference Free variables and bound variables Graph of a function Linear function Radian Rolle's theorem Secant Slope Tangent Limits Indeterminate form Limit of a function One-sided limit Limit of a sequence Order of approximation (ε, δ)-definition of limit Differential calculus Derivative Second derivative Partial derivative Differential Differential operator Mean value theorem Notation Leibniz's notation Newton's notation Rules of differentiation linearity Power Sum Chain L'Hôpital's Product General Leibniz's rule Quotient Other techniques Implicit differentiation Inverse functions and differentiation Logarithmic derivative Related rates Stationary points First derivative test Second derivative test Extreme value theorem Maximum and minimum Further applications Newton's method Taylor's theorem Differential equation Ordinary differential equation Partial differential equation Stochastic differential equation Integral calculus Antiderivative Arc length Riemann integral Basic properties Constant of integration Fundamental theorem of calculus Differentiating under the integral sign Integration by parts Integration by substitution trigonometric Euler Tangent half-angle substitution Partial fractions in integration Quadratic integral Trapezoidal rule Volumes Washer method Shell method Integral equation Integro-differential equation Vector calculus Derivatives Curl Directional derivative Divergence Gradient Laplacian Basic theorems Line integrals Green's Stokes' Gauss' Multivariable calculus Divergence theorem Geometric Hessian matrix Jacobian matrix and determinant Lagrange multiplier Line integral Matrix Multiple integral Partial derivative Surface integral Volume integral Advanced topics Differential forms Exterior derivative Generalized Stokes' theorem Tensor calculus Sequences and series Arithmetico-geometric sequence Types of series Alternating Binomial Fourier Geometric Harmonic Infinite Power Maclaurin Taylor Telescoping Tests of convergence Abel's Alternating series Cauchy condensation Direct comparison Dirichlet's Integral Limit comparison Ratio Root Term Special functions and numbers Bernoulli numbers e (mathematical constant) Exponential function Natural logarithm Stirling's approximation History of calculus Adequality Brook Taylor Colin Maclaurin Generality of algebra Gottfried Wilhelm Leibniz Infinitesimal Infinitesimal calculus Isaac Newton Fluxion Law of Continuity Leonhard Euler Method of Fluxions The Method of Mechanical Theorems Lists Integrals rational functions irrational functions exponential functions logarithmic functions hyperbolic functions inverse trigonometric functions inverse Secant Secant cubed List of limits List of derivatives Miscellaneous topics Complex calculus Contour integral Differential geometry Manifold Curvature of curves of surfaces Tensor Euler–Maclaurin formula Gabriel's horn Integration Bee Proof that 22/7 exceeds π Regiomontanus' angle maximization problem Steinmetz solid v t e Major topics in mathematical analysis Calculus : Integration Differentiation Differential equations ordinary partial stochastic Fundamental theorem of calculus Calculus of variations Vector calculus Tensor calculus Matrix calculus Lists of integrals Table of derivatives Real analysis Complex analysis Hypercomplex analysis ( quaternionic analysis ) Functional analysis Fourier analysis Least-squares spectral analysis Harmonic analysis P-adic analysis ( P-adic numbers ) Measure theory Representation theory Functions Continuous function Special functions Limit Series Infinity Mathematics portal Authority control databases : National Germany Israel United States Japan Czech Republic Retrieved from " https://en.

wikipedia.

org/w/index.

php?title=Derivative&oldid=1223929984#Higher-order_derivatives " Categories : Mathematical analysis Differential calculus Functions and mappings Linear operators in calculus Rates Change Hidden categories: Articles with short description Short description matches Wikidata Wikipedia indefinitely semi-protected pages Good articles Pages using sidebar with the child parameter Pages using multiple image with auto scaled images CS1 Czech-language sources (cs) Articles with GND identifiers Articles with J9U identifiers Articles with LCCN identifiers Articles with NDL identifiers Articles with NKC identifiers This page was last edited on 15 May 2024, at 07:01 (UTC).

Text is available under the Creative Commons Attribution-ShareAlike License 4.

0 ; additional terms may apply.

By using this site, you agree to the Terms of Use and Privacy Policy.

Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc.

, a non-profit organization.

Privacy policy About Wikipedia Disclaimers Contact Wikipedia Code of Conduct Developers Statistics Cookie statement Mobile view.